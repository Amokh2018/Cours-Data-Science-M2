{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9dc0589",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning ‚Äì Titanic Dataset\n",
    "\n",
    "This notebook introduces basic supervised learning with:\n",
    "- Preprocessing (missing values, encoding)\n",
    "- Feature scaling\n",
    "- Pipeline creation with Scikit-learn\n",
    "- Model training & evaluation\n",
    "- Model saving and serving with FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddb9988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c2bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• Load Titanic Dataset\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467288a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßπ Select Features and Target\n",
    "features = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']\n",
    "target = 'Survived'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184e2f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Define Preprocessing Pipeline\n",
    "numeric_features = ['Age', 'Fare']\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÅ Full Pipeline with Model\n",
    "clf_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = clf_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13b6dd7",
   "metadata": {},
   "source": [
    "## Save the Trained Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0fe50c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'joblib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mjoblib\u001b[49m.dump(clf_pipeline, \u001b[33m\"\u001b[39m\u001b[33mtitanic_pipeline.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# üì¶ Imports\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'joblib' is not defined"
     ]
    }
   ],
   "source": [
    "joblib.dump(clf_pipeline, \"titanic_pipeline.pkl\")\n",
    "# üì¶ Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üö¢ Titanic Machine Learning Pipeline - Complete Exercises\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# üì• Load Titanic Dataset\n",
    "print(\"\\nüì• Loading Titanic Dataset...\")\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# üßπ Select Features and Target\n",
    "print(\"\\nüßπ Selecting Features and Target...\")\n",
    "features = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']\n",
    "target = 'Survived'\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "print(f\"Features: {features}\")\n",
    "print(f\"Target: {target}\")\n",
    "\n",
    "# üîß Define Preprocessing Pipeline\n",
    "print(\"\\nüîß Setting up Preprocessing Pipeline...\")\n",
    "numeric_features = ['Age', 'Fare']\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# üîÅ Full Pipeline with Logistic Regression\n",
    "print(\"\\nüîÅ Creating Full Pipeline with Logistic Regression...\")\n",
    "clf_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nüéØ Training Logistic Regression Model...\")\n",
    "clf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = clf_pipeline.predict(X_test)\n",
    "print(\"\\nüìä Logistic Regression Results:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "lr_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {lr_accuracy:.4f}\")\n",
    "\n",
    "# Save the trained pipeline\n",
    "print(\"\\nüíæ Saving the trained pipeline...\")\n",
    "joblib.dump(clf_pipeline, \"titanic_pipeline.pkl\")\n",
    "print(\"‚úÖ Pipeline saved as 'titanic_pipeline.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0bc0e4",
   "metadata": {},
   "source": [
    "## Exercise 1: Try a Different Classifier\n",
    "Replace the logistic regression model in the pipeline with another classifier, such as `RandomForestClassifier`, and compare the results.\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Replace the classifier in clf_pipeline\n",
    "```\n",
    "\n",
    "*What changes do you observe in precision and recall?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891d02dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Random Forest Classifier\n",
    "print(\"\\nüå≤ Training Random Forest Classifier...\")\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "\n",
    "print(\"\\nüìä Random Forest Results:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Accuracy: {rf_accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\nüîç Comparison:\")\n",
    "print(f\"Logistic Regression Accuracy: {lr_accuracy:.4f}\")\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"Improvement: {rf_accuracy - lr_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXERCISE 2: Use Cross-Validation\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e482c4f2",
   "metadata": {},
   "source": [
    "## Exercise 2: Use Cross-Validation\n",
    "Apply cross-validation on the pipeline instead of a single train/test split.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "```\n",
    "\n",
    "*Is the model stable across folds?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68367ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Cross-Validation\n",
    "print(\"\\nüîÑ Performing 5-Fold Cross-Validation...\")\n",
    "\n",
    "# Cross-validation for Logistic Regression\n",
    "cv_scores_lr = cross_val_score(clf_pipeline, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"\\nLogistic Regression CV Scores: {cv_scores_lr}\")\n",
    "print(f\"Mean CV Accuracy: {cv_scores_lr.mean():.4f} (+/- {cv_scores_lr.std() * 2:.4f})\")\n",
    "\n",
    "# Cross-validation for Random Forest\n",
    "cv_scores_rf = cross_val_score(rf_pipeline, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"\\nRandom Forest CV Scores: {cv_scores_rf}\")\n",
    "print(f\"Mean CV Accuracy: {cv_scores_rf.mean():.4f} (+/- {cv_scores_rf.std() * 2:.4f})\")\n",
    "\n",
    "print(f\"\\nüéØ Model Stability Analysis:\")\n",
    "print(f\"Logistic Regression std: {cv_scores_lr.std():.4f}\")\n",
    "print(f\"Random Forest std: {cv_scores_rf.std():.4f}\")\n",
    "print(\"Lower standard deviation indicates more stable model across folds.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXERCISE 3: Add Feature Engineering\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cdea35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e156e8c",
   "metadata": {},
   "source": [
    "## Exercise 3: Add Feature Engineering\n",
    "Add a new column to the Titanic data, such as `FamilySize = SibSp + Parch`, and evaluate if this feature improves the model.\n",
    "\n",
    "```python\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch']\n",
    "# Then include it in the feature list and re-run the pipeline\n",
    "```\n",
    "\n",
    "*Does the new feature improve the prediction metrics?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ded255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Feature Engineering\n",
    "print(\"\\nüîß Adding FamilySize feature...\")\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch']\n",
    "print(f\"FamilySize statistics:\")\n",
    "print(df['FamilySize'].describe())\n",
    "\n",
    "# Update features to include FamilySize\n",
    "features_enhanced = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'FamilySize']\n",
    "X_enhanced = df[features_enhanced]\n",
    "\n",
    "# Update preprocessing pipeline for enhanced features\n",
    "numeric_features_enhanced = ['Age', 'Fare', 'FamilySize']\n",
    "numeric_transformer_enhanced = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor_enhanced = ColumnTransformer([\n",
    "    ('num', numeric_transformer_enhanced, numeric_features_enhanced),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Create enhanced pipeline\n",
    "enhanced_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor_enhanced),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Train and evaluate enhanced model\n",
    "X_train_enh, X_test_enh, y_train_enh, y_test_enh = train_test_split(\n",
    "    X_enhanced, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "enhanced_pipeline.fit(X_train_enh, y_train_enh)\n",
    "y_pred_enh = enhanced_pipeline.predict(X_test_enh)\n",
    "\n",
    "print(\"\\nüìä Enhanced Model Results (with FamilySize):\")\n",
    "print(classification_report(y_test_enh, y_pred_enh))\n",
    "enhanced_accuracy = accuracy_score(y_test_enh, y_pred_enh)\n",
    "print(f\"Enhanced Model Accuracy: {enhanced_accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\nüîç Feature Engineering Impact:\")\n",
    "print(f\"Original Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"Enhanced Model Accuracy: {enhanced_accuracy:.4f}\")\n",
    "print(f\"Improvement: {enhanced_accuracy - rf_accuracy:.4f}\")\n",
    "\n",
    "# Save the enhanced model\n",
    "joblib.dump(enhanced_pipeline, \"titanic_enhanced_pipeline.pkl\")\n",
    "print(\"‚úÖ Enhanced pipeline saved as 'titanic_enhanced_pipeline.pkl'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXERCISE 4: Streamlit Interface Code\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a56405b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0ecf45a",
   "metadata": {},
   "source": [
    "## Exercise 4 (Bonus): Create a Streamlit Interface\n",
    "Build a simple Streamlit UI to load the trained model and predict survival based on user input.\n",
    "\n",
    "```python\n",
    "# Example streamlit interface\n",
    "import streamlit as st\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "model = joblib.load(\"titanic_pipeline.pkl\")\n",
    "Pclass = st.selectbox(\"Pclass\", [1, 2, 3])\n",
    "Sex = st.selectbox(\"Sex\", [\"male\", \"female\"])\n",
    "Age = st.slider(\"Age\", 0, 100, 25)\n",
    "Fare = st.slider(\"Fare\", 0.0, 500.0, 32.0)\n",
    "Embarked = st.selectbox(\"Embarked\", [\"S\", \"C\", \"Q\"])\n",
    "\n",
    "if st.button(\"Predict\"):\n",
    "    X_new = pd.DataFrame([[Pclass, Sex, Age, Fare, Embarked]],\n",
    "                         columns=[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\"])\n",
    "    pred = model.predict(X_new)\n",
    "    st.write(\"Prediction:\", \"Survived\" if pred[0] == 1 else \"Did not survive\")\n",
    "```\n",
    "\n",
    "üëâ *Try running your Streamlit app locally.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efca9103",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit_code = '''\n",
    "# streamlit_titanic_app.py\n",
    "import streamlit as st\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    return joblib.load(\"titanic_enhanced_pipeline.pkl\")\n",
    "\n",
    "def main():\n",
    "    st.title(\"üö¢ Titanic Survival Predictor\")\n",
    "    st.write(\"Predict passenger survival on the Titanic based on passenger characteristics.\")\n",
    "    \n",
    "    # Load model\n",
    "    model = load_model()\n",
    "    \n",
    "    # Create input form\n",
    "    st.sidebar.header(\"Passenger Information\")\n",
    "    \n",
    "    # Input fields\n",
    "    pclass = st.sidebar.selectbox(\"Passenger Class\", [1, 2, 3], \n",
    "                                 help=\"1 = First Class, 2 = Second Class, 3 = Third Class\")\n",
    "    sex = st.sidebar.selectbox(\"Sex\", [\"male\", \"female\"])\n",
    "    age = st.sidebar.slider(\"Age\", 0, 100, 25, help=\"Age in years\")\n",
    "    fare = st.sidebar.slider(\"Fare\", 0.0, 500.0, 32.0, step=0.1, \n",
    "                            help=\"Ticket fare in pounds\")\n",
    "    embarked = st.sidebar.selectbox(\"Port of Embarkation\", [\"S\", \"C\", \"Q\"],\n",
    "                                   help=\"S = Southampton, C = Cherbourg, Q = Queenstown\")\n",
    "    \n",
    "    # Calculate family size (SibSp + Parch equivalent)\n",
    "    sibsp = st.sidebar.number_input(\"Siblings/Spouses aboard\", 0, 8, 1)\n",
    "    parch = st.sidebar.number_input(\"Parents/Children aboard\", 0, 6, 0)\n",
    "    family_size = sibsp + parch\n",
    "    \n",
    "    st.sidebar.write(f\"**Family Size: {family_size}**\")\n",
    "    \n",
    "    # Display passenger summary\n",
    "    st.subheader(\"Passenger Summary\")\n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    with col1:\n",
    "        st.write(f\"**Class:** {pclass}\")\n",
    "        st.write(f\"**Sex:** {sex}\")\n",
    "        st.write(f\"**Age:** {age}\")\n",
    "    \n",
    "    with col2:\n",
    "        st.write(f\"**Fare:** ¬£{fare:.2f}\")\n",
    "        st.write(f\"**Embarked:** {embarked}\")\n",
    "        st.write(f\"**Family Size:** {family_size}\")\n",
    "    \n",
    "    # Prediction\n",
    "    if st.button(\"üéØ Predict Survival\", type=\"primary\"):\n",
    "        # Create DataFrame for prediction\n",
    "        X_new = pd.DataFrame([[pclass, sex, age, fare, embarked, family_size]],\n",
    "                           columns=[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\"])\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(X_new)[0]\n",
    "        probability = model.predict_proba(X_new)[0]\n",
    "        \n",
    "        # Display results\n",
    "        st.subheader(\"Prediction Results\")\n",
    "        \n",
    "        if prediction == 1:\n",
    "            st.success(\"üéâ **SURVIVED** - This passenger would have likely survived!\")\n",
    "            st.write(f\"Survival Probability: **{probability[1]:.2%}**\")\n",
    "        else:\n",
    "            st.error(\"üíî **DID NOT SURVIVE** - This passenger would have likely perished.\")\n",
    "            st.write(f\"Survival Probability: **{probability[1]:.2%}**\")\n",
    "        \n",
    "        # Show probability bar\n",
    "        st.subheader(\"Probability Breakdown\")\n",
    "        col1, col2 = st.columns(2)\n",
    "        with col1:\n",
    "            st.metric(\"Survival\", f\"{probability[1]:.2%}\")\n",
    "        with col2:\n",
    "            st.metric(\"Death\", f\"{probability[0]:.2%}\")\n",
    "        \n",
    "        # Progress bar\n",
    "        st.progress(probability[1])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "print(\"üìù Streamlit App Code Generated!\")\n",
    "print(\"\\nTo run the Streamlit app:\")\n",
    "print(\"1. Save the above code as 'streamlit_titanic_app.py'\")\n",
    "print(\"2. Install streamlit: pip install streamlit\")\n",
    "print(\"3. Run: streamlit run streamlit_titanic_app.py\")\n",
    "\n",
    "# Save streamlit code to file\n",
    "with open(\"streamlit_titanic_app.py\", \"w\") as f:\n",
    "    f.write(streamlit_code)\n",
    "print(\"‚úÖ Streamlit app saved as 'streamlit_titanic_app.py'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ SUMMARY OF RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Model Performance Comparison:\")\n",
    "print(f\"1. Logistic Regression:     {lr_accuracy:.4f}\")\n",
    "print(f\"2. Random Forest:           {rf_accuracy:.4f}\")\n",
    "print(f\"3. Enhanced RF (FamilySize): {enhanced_accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\nüîÑ Cross-Validation Results:\")\n",
    "print(f\"‚Ä¢ Logistic Regression CV: {cv_scores_lr.mean():.4f} ¬± {cv_scores_lr.std():.4f}\")\n",
    "print(f\"‚Ä¢ Random Forest CV:       {cv_scores_rf.mean():.4f} ¬± {cv_scores_rf.std():.4f}\")\n",
    "\n",
    "print(f\"\\nüöÄ Key Insights:\")\n",
    "print(\"‚Ä¢ Random Forest generally outperformed Logistic Regression\")\n",
    "print(\"‚Ä¢ Adding FamilySize feature provided additional improvement\")\n",
    "print(\"‚Ä¢ Cross-validation showed model stability across folds\")\n",
    "print(\"‚Ä¢ Streamlit app ready for interactive predictions\")\n",
    "\n",
    "print(f\"\\nüìÅ Files Created:\")\n",
    "print(\"‚Ä¢ titanic_pipeline.pkl (Original LR model)\")\n",
    "print(\"‚Ä¢ titanic_enhanced_pipeline.pkl (Enhanced RF model)\")\n",
    "print(\"‚Ä¢ streamlit_titanic_app.py (Interactive web app)\")\n",
    "\n",
    "print(\"\\nüéâ All exercises completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab42845d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
